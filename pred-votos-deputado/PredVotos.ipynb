{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando dados e separando pelo ano ex: 2006 e 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando os dados - Como sugerido 2006 treino e 2010 validação\n",
    "# train = pd.read_csv(\"./xaa.csv\")\n",
    "# Dados de 2010\n",
    "# test = pd.read_csv(\"./xab.csv\")\n",
    "\n",
    "points = pd.read_csv(\"./eleicoes.csv\")\n",
    "\n",
    "# points = pd.concat((points, pd.read_csv(\"./eleicoes_2014.csv\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré processamento dos dados\n",
    "\n",
    "1. Substituindo NaN's pela média.\n",
    "2. Criando variáveis númericas a partir das variáveis categóricas\n",
    "3. Normalizando features utilizando log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (10.0, 7.0)\n",
    "\n",
    "#histograma das variáveis numéricas\n",
    "dist_feats = pd.DataFrame({ \"quantidade_doacoes\":points[\"quantidade_doacoes\"],\n",
    "                            \"quantidade_doadores\":points[\"quantidade_doadores\"],\n",
    "                            \"total_receita\":points[\"total_receita\"],\n",
    "                            \"media_receita\":points[\"media_receita\"],\n",
    "                            \"recursos_de_outros_candidatos/comites\":points[\"recursos_de_outros_candidatos/comites\"],\n",
    "                            \"quantidade_despesas\":points[\"quantidade_despesas\"],\n",
    "                            \"quantidade_fornecedores\":points[\"quantidade_fornecedores\"],\n",
    "                            \"total_despesa\":points[\"total_despesa\"],\n",
    "                            \"media_despesa\":points[\"media_despesa\"],\n",
    "                          })\n",
    "\n",
    "hits = dist_feats.hist(log=True, xlabelsize=0, ylabelsize=0)\n",
    "\n",
    "\n",
    "total_votos_2006 = pd.DataFrame({\"total_votos\":points[\"votos\"], \"log(total_votos + 1)\":np.log1p(points[\"votos\"])})\n",
    "total_votos_2006.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando TODOS os dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Removendo colunas sem importância\n",
    "points = points.drop(columns=['sequencial_candidato', 'nome', 'media_receita', 'media_despesa'])\n",
    "\n",
    "# Coletando variáveis numéricas\n",
    "numeric_feats = points.dtypes[points.dtypes != \"object\"].index\n",
    "\n",
    "# calculando skew\n",
    "skewed_feats = points[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.index\n",
    "\n",
    "# Preenchendo valores com a media\n",
    "points = points.fillna(points.mean())\n",
    "\n",
    "# Regularizando variaveis, exceto a variável ano.\n",
    "points[numeric_feats[1 :]] = np.log1p(points[numeric_feats[1:]])\n",
    "\n",
    "# Transformando variáveis categóricas\n",
    "points = pd.get_dummies(points)\n",
    "\n",
    "# Filtrando dados utilizados no treino e na validação\n",
    "X = points.loc[points['ano'] != 2014].drop(columns=['votos'])\n",
    "Y = points.loc[points['ano'] != 2014].votos\n",
    "\n",
    "# Colhendo amostra aleatória dos dados\n",
    "train, validation, y_train, y_validation = train_test_split(X, Y, random_state = 8)\n",
    "\n",
    "# Dados de 2014\n",
    "# points_2014 = points.loc[points['ano'] == 2014]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# RMSE Cross Validation Function\n",
    "def rmse_cv(model):\n",
    "    rmse = np.sqrt(-cross_val_score(model, train, y_train, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "depths = np.arange(1,15,1).tolist()\n",
    "cv_treeregressor = [rmse_cv(DecisionTreeRegressor(max_depth = depth )).mean() \n",
    "            for depth in depths]\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "cv_treeregressor = pd.Series(cv_treeregressor, index = depths)\n",
    "cv_treeregressor.plot(title = \"Validation - Just Do It\")\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel(\"rmse\")\n",
    "print(\"A profundidade ideal é {0}, com rmse = {1}\".format(cv_treeregressor.idxmin(), cv_treeregressor.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge = Ridge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.05, 0.1, 0.3, 1, 3, 5, 7, 10, 13, 15, 30, 50, 75]\n",
    "cv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n",
    "            for alpha in alphas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ridge = pd.Series(cv_ridge, index = alphas)\n",
    "cv_ridge.plot(title = \"Validation - Just Do It\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ridge.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = LassoCV(alphas = [0.001, 0.005, 0.01, 0.05, 0.5, 1]).fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv(model_lasso).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(model_lasso.coef_, index = train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_coef = pd.concat([coef.sort_values().head(10),\n",
    "                     coef.sort_values().tail(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the residuals as well:\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "preds = pd.DataFrame({\"preds\":model_lasso.predict(train), \"true\":y_train})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "reg_linear = LinearRegression()\n",
    "rmse_cv(reg_linear).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_linear = LinearRegression().fit(train, y_train)\n",
    "preds = pd.DataFrame({\"preds\": model_reg_linear.predict(validation), \"true\":y_validation})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\", grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "neighbors = np.arange(15,35,1).tolist()\n",
    "\n",
    "cv_knn = [rmse_cv(KNeighborsRegressor(n_neighbors=neighbor)).mean() \n",
    "            for neighbor in neighbors]\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "cv_knn = pd.Series(cv_knn, index = neighbors)\n",
    "cv_knn.plot(title = \"Validation - Just Do It\")\n",
    "plt.xlabel(\"knn\")\n",
    "plt.ylabel(\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsRegressor(n_neighbors = cv_knn.idxmin()).fit(train, y_train)\n",
    "preds = pd.DataFrame({\"preds\": model_knn.predict(validation), \"true\":y_validation})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\", grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train, label = y_train)\n",
    "dtest = xgb.DMatrix(validation)\n",
    "\n",
    "params = {\"max_depth\":2, \"eta\":0.1}\n",
    "model = xgb.cv(params, dtrain,  num_boost_round=500, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.loc[30:,[\"test-rmse-mean\", \"train-rmse-mean\"]].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1) #the params were tuned using xgb.cv\n",
    "model_xgb.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds = np.expm1(model_xgb.predict(validation))\n",
    "lasso_preds = np.expm1(model_lasso.predict(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"xgb\":xgb_preds, \"lasso\":lasso_preds})\n",
    "predictions.plot(x = \"xgb\", y = \"lasso\", kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = 0.7*lasso_preds + 0.3*xgb_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution = pd.DataFrame({\"id\":validation.nome, \"Votos\":preds, \"ano\":validation.ano})\n",
    "# solution.to_csv(\"÷ridge_sol.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resíduos X Predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the residual vs predictions values of the model\n",
    "def plot_res_vs_pred(model, x, y):\n",
    "    y_pred = model.predict(x)\n",
    "    res = y - y_pred\n",
    "    #printando rmse\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    print(\"RMSE : {0}\".format(rmse))\n",
    "    #plotando resíduos\n",
    "    matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "    plt.plot(y_pred, res, 'k.', color='blue')\n",
    "    plt.axhline(y = 0., color = 'r', linestyle = '-')\n",
    "    plt.xlabel(\"Predictions\")\n",
    "    plt.ylabel(\"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "model_reg_linear = LinearRegression().fit(train, y_train)\n",
    "plot_res_vs_pred(model_reg_linear, validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge = Ridge(alpha = cv_ridge.idxmin()).fit(train, y_train)\n",
    "plot_res_vs_pred(model_ridge, validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo Ridge apresenta boa adequação ao problema, sua distribuição de resíduos é aleatória e em torno de 0, com rmse relativamente baixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = LassoCV(alphas = [0.001, 0.005, 0.01, 0.05, 0.5, 1]).fit(train, y_train)\n",
    "plot_res_vs_pred(model_lasso, validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O modelo lasso não apresenta padrões perceptíveis em sua distribuição que está distribuida em torno de 0, isso indica uma boa adequação do modelo ao problema em questão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsRegressor(n_neighbors = cv_knn.idxmin()).fit(train, y_train)\n",
    "plot_res_vs_pred(model_knn, validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O KNN não apresenta padrões claros em sua distribuição de resíduos. Por possuir um rsme mais alto que Ridge e Lasso, ele não possui uma distribuição tão concentrada em torno de 0 quanto esses. Com isso ele é menos adequado ao problema do que os outros modelos já testados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeRegressor(max_depth = cv_treeregressor.idxmin()).fit(train, y_train)\n",
    "plot_res_vs_pred(model_tree, validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O plot dos resíduos para o modelo árvore de decisão apresenta padrões. Por se tratar de um modelo de classificação, para candidatos com dados relativamente parecidos o modelo preve a mesma quantidade de votos. Em outras palavras, ele cria categorias, faixas de valores para os votos, e associa a candidatos relativamente parecidos.\n",
    "\n",
    "Assim, seu plot de resíduos e alto rmse indica uma inadequação do modelo ao problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1) #the params were tuned using xgb.cv\n",
    "model_xgb.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_vs_pred(model_xgb, train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão eleições 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o CSV novamente\n",
    "\n",
    "points = pd.read_csv(\"./eleicoes.csv\")\n",
    "\n",
    "# Concatenando o CSV com os dados de 2014\n",
    "points = pd.concat((points, pd.read_csv(\"./eleicoes_2014.csv\")))\n",
    "\n",
    "# Tratando TODOS os dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "points = points.drop(columns=['sequencial_candidato', 'nome', 'media_receita', 'media_despesa'])\n",
    "\n",
    "numeric_feats = points.dtypes[points.dtypes != \"object\"].index\n",
    "\n",
    "# calculando skew\n",
    "skewed_feats = points[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.index\n",
    "\n",
    "# Preenchendo valores com a media\n",
    "points = points.fillna(points.mean())\n",
    "\n",
    "# Regularizando variaveis, exceto a variável ano.\n",
    "points[numeric_feats[1 :]] = np.log1p(points[numeric_feats[1:]])\n",
    "\n",
    "# Transformando variáveis categóricas\n",
    "points = pd.get_dummies(points)\n",
    "\n",
    "# Filtrando dados utilizados no treino e na validação\n",
    "X = points.loc[points['ano'] != 2014].drop(columns=['votos'])\n",
    "Y = points.loc[points['ano'] != 2014].votos\n",
    "\n",
    "# Colhendo amostra aleatória dos dados\n",
    "train, validation, y_train, y_validation = train_test_split(X, Y, random_state = 8)\n",
    "\n",
    "# Dados de 2014\n",
    "points_2014 = points.loc[points['ano'] == 2014]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge = Ridge(alpha = cv_ridge.idxmin()).fit(points.drop(columns=['votos']), points.votos)\n",
    "preds = pd.DataFrame({\"preds\": model_ridge.predict(points_2014.drop(columns=['votos'])), \"true\":points_2014.votos})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\", grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = LassoCV(alphas = [0.001, 0.005, 0.01, 0.05, 0.5, 1]).fit(points.drop(columns=['votos']), points.votos)\n",
    "preds = pd.DataFrame({\"preds\": model_lasso.predict(points_2014.drop(columns=['votos'])), \"true\":points_2014.votos})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\", grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
